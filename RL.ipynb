{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920f787c-e17e-499f-abab-7b399f1c6472",
   "metadata": {},
   "source": [
    "# Projet apprentissage par renforcement: Q-learning : Space Invaders\n",
    "\n",
    "- YATTE Cyrille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166174f-f62e-4a8b-8b02-81d3311a88f3",
   "metadata": {},
   "source": [
    "- Bienvenue dans le monde de Space Invaders, un jeu vidéo classique développé et publié par Taito en 1978. \n",
    "C'était l'un des premiers jeux d'arcade à connaître un grand succès et à devenir populaire auprès du grand public. \n",
    "Il a également été l'un des premiers jeux vidéo à utiliser des graphismes en 2D et un son monophonique.\n",
    "\n",
    "- Dans ce jeu de science-fiction amusant et excitant, vous incarnez un combattant spatial qui doit défendre la Terre contre une armée d'envahisseurs extraterrestres.\n",
    "Les envahisseurs viennent vers vous en ligne, essayant de vous toucher avec leurs rayons laser, et votre mission est de les détruire tous avant qu'ils n'atteignent le sol.\n",
    "Vous contrôlez votre vaisseau spatial avec les flèches de direction de votre clavier ou de votre manette de jeu et appuyez sur la touche \"espace\" pour tirer sur les envahisseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ac31b-7003-4880-bd78-29def92d23d2",
   "metadata": {},
   "source": [
    "## STEP 0: INSTALLATION DE PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae820e66-7966-4499-b327-9be25400861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: gym in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: keras-rl2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.16.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (23.1.21)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (15.0.6.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.22.1)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (63.4.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.51.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.7.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: ale-py~=0.7.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gym) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from ale-py~=0.7.1->gym) (4.13.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\dell\\anaconda3\\lib\\site-packages (from ale-py~=0.7.1->gym) (5.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.37.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py~=0.7.1->gym) (3.8.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.9.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.0.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.16.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12.0 gym keras-rl2 gym[atari]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d71048-db10-4d29-9da1-d0ee8868e32b",
   "metadata": {},
   "source": [
    "## STEP 1: CREATION ENVIRONNEMENT AVEC OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110ce3ee-4b25-446b-961c-a1137401d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eac34b6-a415-4979-8af5-f7e88b008a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76445ec1-a55f-4cd1-9783-bb1cdd4cfc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b4689c-37c1-4812-a10a-18685e5a7333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\gym\\envs\\atari\\environment.py:267: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:155.0\n",
      "Episode:2 Score:80.0\n",
      "Episode:3 Score:415.0\n",
      "Episode:4 Score:85.0\n",
      "Episode:5 Score:65.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0,1,2,3,4,5])\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6fd4e-7771-4c50-afe6-28227ade6946",
   "metadata": {},
   "source": [
    "## STEP 3: LA CREATION D'UN AGENT: Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdb1ae-ff42-4bc1-bcec-c2f21de0ff5b",
   "metadata": {},
   "source": [
    "#### Step 3-1: Création du modèle du deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7225aebc-2b3a-469b-b0c3-004998856109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a08a24-aee1-4412-a9a1-d6f79621f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=(3,height, width, channels)))\n",
    "    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d250ff-e623-49f3-915b-8c2e504a5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(height, width, channels, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08322586-9419-40d6-a93e-f59953ca6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 3, 51, 39, 32)     6176      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 24, 18, 64)     32832     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 22, 16, 64)     36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 67584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               34603520  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,812,326\n",
      "Trainable params: 34,812,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb94e659-9847-40af-b5fc-41a931cf4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d68ea9e-16a2-41ec-87ea-bd56c65bea29",
   "metadata": {},
   "source": [
    "#### Step 3-2: Création de l'agent avec le Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f37164-7ef4-4f01-9f24-066d4ff05a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
    "    memory = SequentialMemory(limit=1000, window_length=3)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  enable_dueling_network=True, dueling_type='avg', \n",
    "                   nb_actions=actions, nb_steps_warmup=1000\n",
    "                  )\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17169c06-32dc-4fb1-b885-6ef100cb3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=0.0004))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b50216e-1ddf-4f80-a883-dc6eff8b421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  629/10000: episode: 1, duration: 27.540s, episode steps: 629, steps per second:  23, episode reward: 180.000, mean reward:  0.286 [ 0.000, 30.000], mean action: 2.564 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1719/10000: episode: 2, duration: 1789.902s, episode steps: 1090, steps per second:   1, episode reward: 435.000, mean reward:  0.399 [ 0.000, 200.000], mean action: 2.422 [0.000, 5.000],  loss: 78.770140, mean_q: 13.385782, mean_eps: 0.877645\n",
      " 2845/10000: episode: 3, duration: 2577.889s, episode steps: 1126, steps per second:   0, episode reward: 190.000, mean reward:  0.169 [ 0.000, 30.000], mean action: 2.401 [0.000, 5.000],  loss: 0.944055, mean_q: 12.790775, mean_eps: 0.794665\n",
      " 3794/10000: episode: 4, duration: 2044.362s, episode steps: 949, steps per second:   0, episode reward: 260.000, mean reward:  0.274 [ 0.000, 30.000], mean action: 2.579 [0.000, 5.000],  loss: 0.588588, mean_q: 11.989770, mean_eps: 0.701290\n",
      " 4287/10000: episode: 5, duration: 1522.924s, episode steps: 493, steps per second:   0, episode reward: 165.000, mean reward:  0.335 [ 0.000, 30.000], mean action: 2.347 [0.000, 5.000],  loss: 0.461232, mean_q: 11.312949, mean_eps: 0.636400\n",
      " 5104/10000: episode: 6, duration: 2093.390s, episode steps: 817, steps per second:   0, episode reward: 155.000, mean reward:  0.190 [ 0.000, 30.000], mean action: 2.361 [0.000, 5.000],  loss: 0.464607, mean_q: 11.566773, mean_eps: 0.577450\n",
      " 6294/10000: episode: 7, duration: 2999.327s, episode steps: 1190, steps per second:   0, episode reward: 240.000, mean reward:  0.202 [ 0.000, 30.000], mean action: 2.285 [0.000, 5.000],  loss: 0.384183, mean_q: 12.233955, mean_eps: 0.487135\n",
      " 7323/10000: episode: 8, duration: 2089.414s, episode steps: 1029, steps per second:   0, episode reward: 225.000, mean reward:  0.219 [ 0.000, 30.000], mean action: 2.502 [0.000, 5.000],  loss: 0.457930, mean_q: 11.043482, mean_eps: 0.387280\n",
      " 7978/10000: episode: 9, duration: 1587.822s, episode steps: 655, steps per second:   0, episode reward: 105.000, mean reward:  0.160 [ 0.000, 25.000], mean action: 2.847 [0.000, 5.000],  loss: 0.260256, mean_q: 11.732232, mean_eps: 0.311500\n",
      " 8683/10000: episode: 10, duration: 1638.729s, episode steps: 705, steps per second:   0, episode reward: 335.000, mean reward:  0.475 [ 0.000, 200.000], mean action: 2.803 [0.000, 5.000],  loss: 2.170351, mean_q: 11.059139, mean_eps: 0.250300\n",
      " 9559/10000: episode: 11, duration: 1806.364s, episode steps: 876, steps per second:   0, episode reward: 300.000, mean reward:  0.342 [ 0.000, 30.000], mean action: 2.516 [0.000, 5.000],  loss: 4.394583, mean_q: 11.469028, mean_eps: 0.179155\n",
      "done, took 21381.863 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b351d02490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff4510-9328-4a5f-a792-d57b0d84e1d7",
   "metadata": {},
   "source": [
    "#### Step 3-3: Le test du jeu Space Invaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7612e87d-7bba-400f-b92e-4d852d40041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\gym\\envs\\atari\\environment.py:267: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: 320.000, steps: 702\n",
      "Episode 2: reward: 460.000, steps: 978\n",
      "Episode 3: reward: 110.000, steps: 615\n",
      "Episode 4: reward: 105.000, steps: 673\n",
      "Episode 5: reward: 120.000, steps: 647\n",
      "Episode 6: reward: 450.000, steps: 1115\n",
      "Episode 7: reward: 55.000, steps: 700\n",
      "Episode 8: reward: 215.000, steps: 844\n",
      "Episode 9: reward: 95.000, steps: 667\n",
      "Episode 10: reward: 105.000, steps: 599\n",
      "203.5\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a518fb0-1659-405c-8e30-39a8e7fa4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('C:/Users/dell/Desktop/Msc_ENSAI/dqn_weights.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1a4219-dc5c-4d23-847d-e8711f3d0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('C:/Users/dell/Desktop/Msc_ENSAI/dqn_weights.h5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
